<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="LakshmanTutorials">
<title>Multiple Testing Correction • LakshmanTutorials</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Multiple Testing Correction">
<meta property="og:description" content="LakshmanTutorials">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">LakshmanTutorials</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="https://www.ahl27.com/OtherTutorials">Overview</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-tutorials">Tutorials</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-tutorials">
    <a class="dropdown-item" href="https://www.ahl27.com/OtherTutorials/articles/BuildingTrees.html">Building Trees</a>
    <a class="dropdown-item" href="https://www.ahl27.com/OtherTutorials/articles/ComparingTrees.html">Comparing Trees</a>
    <a class="dropdown-item" href="https://www.ahl27.com/OtherTutorials/articles/MultipleTesting.html">Multiple Testing Correction</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://www.ahl27.com/tutorials">Back to Website</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/ahl27/OtherTutorials" aria-label="GitHub">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://www.ahl27.com" aria-label="My Website">
    <span class="fa fa-home"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Multiple Testing Correction</h1>
                        <h4 data-toc-skip class="author">Aidan
Lakshman<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;&lt;a href="mailto:ahl27@pitt.edu" class="email"&gt;ahl27@pitt.edu&lt;/a&gt;&lt;/p&gt;'><sup>1</sup></a>
</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/ahl27/OtherTutorials/blob/HEAD/vignettes/MultipleTesting.Rmd" class="external-link"><code>vignettes/MultipleTesting.Rmd</code></a></small>
      <div class="d-none name"><code>MultipleTesting.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span>rmarkdown.html_vignette.check_title <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p>Statistical tests typically follow the same formula: we have a null
hypothesis <span class="math inline">\(H_0\)</span> and an alternative
hypothesis <span class="math inline">\(H_A\)</span>, and then we do some
math and determine a p-value <span class="math inline">\(p\)</span>.
Here <span class="math inline">\(p\)</span> represents the probability
of obtaining results at least as the ones observed assuming the null
hypothesis is true. In other words, how likely are we to observe a
result this extreme purely due to chance? If <span class="math inline">\(p &lt; \alpha\)</span> for some significance level
<span class="math inline">\(\alpha\)</span> (typically 0.05), then we
reject <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_A\)</span>. For example, if we roll a dice and
get two sixes in a row, that would be surprising, but not <em>that</em>
surprising. However, if we got 25 sixes in a row, we’d start to question
if the die is actually fair.</p>
<p><img src="dice_illustration.png"></p>
<p>If we start making multiple tests, however, the problem becomes more
complicated. Single statistical tests measure the probability we would
have observed a result due to chance–as we run increasingly more
statistical inferences, the <em>probability</em> that we observe an
extreme result becomes the <em>proportion</em> of our results that are
that extreme. At <span class="math inline">\(\alpha=0.05\)</span>
significance, 5% of our tests will incorrectly reject the null
hypotheses.</p>
<p><a href="https://en.wikipedia.org/wiki/Multiple_comparisons_problem#Definition" class="external-link">Wikipedia</a>
cites an example where we test whether a drug decreases any one of a
number of disease symptoms. If we test a single symptom, rejecting the
null is significant. However, as we increase the number of symptoms we
check, the probability of observing a spurious correlation between drug
and a random symptom increases. If we check 100 symptoms and all tests
are independent, the probability of at least one incorrect rejection is
over 99%.</p>
<p>This begs the question–how can we protect against error introduced by
multiple testing?</p>
<div class="section level2">
<h2 id="types-of-error">Types of Error<a class="anchor" aria-label="anchor" href="#types-of-error"></a>
</h2>
<p>Before we talk about correction procedures, we first need to talk
about what “error” means. For single statistical tests, we’re typically
worried about Type I and Type II error.</p>
<p>A Type I error is where we incorrectly reject the null hypothesis.
This is when we observed a striking result due to chance, leading a
false positive. In single statistical tests, the probability of a Type I
error is the significance level (so for <span class="math inline">\(\alpha=0.05\)</span>, it’s 5%).</p>
<p>Type II error is the inverse–we fail to reject the null hypothesis
when we should have rejected. This is when a normally extreme process
happens to produce a normal looking result by chance, leading to a false
negative. In single statistical tests, the probability of a Type II
error is called <span class="math inline">\(\beta\)</span>. The
<strong>power</strong> of a statistical test is given by <span class="math inline">\(1-\beta\)</span>.</p>
<p><img src="MultipleTesting_files/figure-html/unnamed-chunk-1-1.png" width="700"></p>
<p>When we move into multiple testing, we instead examine the
Family-Wise Error Rate (<strong>FWER</strong>) and the False Discovery
Rate (<strong>FDR</strong>). Multiple testing correction is often a
trade-off between minimizing FWER and FDR.</p>
<p>FWER is the probability of making <em>at least one</em> Type I error
within a group of tests. Suppose we have <span class="math inline">\(n\)</span> tests–if each individual test has a
Type I error rate of <span class="math inline">\(\alpha\)</span> and all
tests are independent, the FWER (<span class="math inline">\(\bar
\alpha\)</span>) is simply: <span class="math display">\[ \bar \alpha =
1 - (1-\alpha)^n\]</span></p>
<p>FDR is the expected proportion of Type I errors across all tests. Put
in terms of true/false positives:</p>
<p><span class="math display">\[ FDR = \frac{FP}{FP+TP} \]</span>
Corrections that minimize FDR result in higher statistical power at the
cost of more Type I errors. Minimizing FWER does the opposite; fewer
Type I errors, but lower statistical power.</p>
</div>
<div class="section level2">
<h2 id="minimizing-fwer-for-multiple-hypotheses">Minimizing FWER for Multiple Hypotheses<a class="anchor" aria-label="anchor" href="#minimizing-fwer-for-multiple-hypotheses"></a>
</h2>
<div class="section level3">
<h3 id="bonferroni-correction">Bonferroni Correction<a class="anchor" aria-label="anchor" href="#bonferroni-correction"></a>
</h3>
<p>Bonferroni correction is one of the simplest ways to minimize FWER
across multiple tests. The motivation for this method comes from <a href="https://en.wikipedia.org/wiki/Boole%27s_inequality" class="external-link">Boole’s
Inequality</a>, which implies the following result for <span class="math inline">\(n\)</span> <em>independent</em> tests:</p>
<p><span class="math display">\[\bar \alpha \leq n\alpha\]</span></p>
<p>By solving this equation for <span class="math inline">\(\alpha\)</span>, we see that if we set <span class="math inline">\(\alpha = \frac{\bar \alpha}{n}\)</span>, we can
constrain the FWER to any value we’d like. For example, to ensure FWER
of at most 0.1 across 100 tests, we simply test for significance at the
<span class="math inline">\(\alpha = \frac{0.01}{100} = 10^{-4}\)</span>
significance level.</p>
<p>This method is very simple, but comes with some drawbacks. Most
notably, the result depends on the fact that the individual tests are
independent–if any test is dependent, the correction is more
conservative than necessary. Bonferroni correction also has less
statistical power than some alternatives, like Holm-Bonferrroni or Šidák
correction.</p>
</div>
<div class="section level3">
<h3 id="šidák-correction">Šidák Correction<a class="anchor" aria-label="anchor" href="#%C5%A1id%C3%A1k-correction"></a>
</h3>
<p>The Šidák correction is slightly less stringent than Bonferroni
correction while still conserving a fixed FWER rate. For this procedure,
we instead back solve the initial calculation of FWER:</p>
<p><span class="math display">\[\begin{align*}
\bar \alpha &amp;= 1 - (1-\alpha)^n \\
\implies \alpha &amp;= 1 - (1-\bar \alpha)^\frac{1}{n}
\end{align*}\]</span></p>
<p>For our previous example of 100 tests at desired FWER of 0.1, we’d
test for significance at the <span class="math inline">\(\alpha =
1-(1-0.1)^{0.01} = 0.00105\)</span> level, which is slightly higher than
Bonferroni’s <span class="math inline">\(0.001\)</span> significance
level. Note that this test also requires independence of the individual
statistical tests.</p>
</div>
<div class="section level3">
<h3 id="holm-bonferroni">Holm-Bonferroni<a class="anchor" aria-label="anchor" href="#holm-bonferroni"></a>
</h3>
<p>Holm-Bonferroni is an improvement on Bonferroni correction that is
uniformly more powerful, meaning that it is always as least as powerful
as Bonferroni. This method employs a sorting of the p-values for a set
of null hypotheses.</p>
<p>To do Holm-Bonferroni correction, we first sort p-values <span class="math inline">\(p_1,\dots,p_n\)</span> such that <span class="math inline">\(p_i \leq p_{i+1} \;\forall i\)</span>. We also
sort our null hypotheses correspondingly into <span class="math inline">\(H_1,\dots,H_n\)</span>. Then, for each <span class="math inline">\(p_k\)</span>, we test if <span class="math inline">\(p_k &lt; \frac{\bar \alpha}{n+1-k}\)</span>. If it
is, we reject <span class="math inline">\(H_k\)</span> and continue on
to <span class="math inline">\(p_{k+1}\)</span>. If not, then we stop
and cannot reject any further hypotheses.</p>
<p>Holm-Bonferroni notably does not require each statistical test to be
independent; it functions correctly under any dependence structure of
the p-values.</p>
</div>
<div class="section level3">
<h3 id="hochberg-step-up">Hochberg Step-Up<a class="anchor" aria-label="anchor" href="#hochberg-step-up"></a>
</h3>
<p>A subtly different test is the Hochberg step-up procedure, which is
uniformly more powerful than Holm-Bonferroni but requires each test to
be statistically independent or positively dependent. The procedure is
the same as Holm-Bonferroni, but instead of iteratively testing
p-values, we find the maximal <span class="math inline">\(k\)</span>
such that <span class="math inline">\(p_k &lt; \frac{\bar
\alpha}{n+1-k}\)</span>, then reject null hypotheses <span class="math inline">\(H_1,\dots,H_k\)</span>.</p>
</div>
</div>
<div class="section level2">
<h2 id="minimizing-fwer-for-one-hypothesis">Minimizing FWER for One Hypothesis<a class="anchor" aria-label="anchor" href="#minimizing-fwer-for-one-hypothesis"></a>
</h2>
<p>These methods are slightly different in that they tests whether
<em>groups</em> of p-values are statistically significant, rather than
examining individual p-values and null hypotheses. Thus, these methods
are ideal for situations where several statistical tests are conducted
on the same overall null hypothesis.</p>
<div class="section level3">
<h3 id="fishers-method">Fisher’s Method<a class="anchor" aria-label="anchor" href="#fishers-method"></a>
</h3>
<p>Fisher’s Method is different from previously mentioned methods in
that it tests whether <em>groups</em> of p-values are statistically
significant, rather than examining individual methods. The method
calculates a test statistic as:</p>
<p><span class="math display">\[ \chi_{2n}^2 \sim -2\sum_{i=1}^n \log
{p_i} \]</span> This formula follows from the fact that, under
independent unbiased statistical tests, the distribution of p-values
should be uniformly distributed on <span class="math inline">\([0,1]\)</span>. A negative log-transform of a
uniformly distributed variable produces an exponential distribution, and
scaling it by two yields a chi-squared distributions with two degrees of
freedom. Summing <span class="math inline">\(n\)</span> chi-squared
distributions with two degrees of freedom produces a chi-squared
distribution with <span class="math inline">\(2n\)</span> degrees of
freedom. From this statistic and distribution, it is simple to calculate
an overall p-value for the set of statistical tests.</p>
<p>Note that this calculation depends on the statistical tests being
independent from each other. If the p-values have any dependence,
Fisher’s Method will produce a result that is anti-conservative, meaning
that it will occasionally incorrectly reject the null hypothesis.
Additionally, Fisher’s Method will overstate evidence against the null
hypothesis in cases where the null is correctly rejected.</p>
</div>
<div class="section level3">
<h3 id="browns-method">Brown’s Method<a class="anchor" aria-label="anchor" href="#browns-method"></a>
</h3>
<p>Brown’s Method improves on Fisher’s Method for cases where p-values
are not independent but the covariance structure of the data <span class="math inline">\(X\)</span> is known. In this case, we can replace
the <span class="math inline">\(\chi^2(n)\)</span> distribution with a
scaled chi-squared distribution <span class="math inline">\(c\chi^2(n')\)</span>, where the new constants
are calculated as:</p>
<p><span class="math display">\[\begin{align*}
c &amp;= \frac{Var(X)}{2E[X]}\\&amp;\\
n' &amp;= \frac{2\left(E[X]\right)^2}{Var(X)}
\end{align*}\]</span></p>
<p>This is often the best approximation if the data are generated from a
multivariate normal distribution with known covariance, but this is a
fairly specific situation.</p>
</div>
<div class="section level3">
<h3 id="cauchy-combination-test">Cauchy Combination Test<a class="anchor" aria-label="anchor" href="#cauchy-combination-test"></a>
</h3>
<p>Instead of transforming the p-values to a <span class="math inline">\(\chi^2\)</span> distribution, a tangent
transformation can transform the data to a distribution with a tail that
is approximately a Cauchy distribution allowing for arbitrary dependence
between the p-values. The test statistic is given by:</p>
<p><span class="math display">\[X = \sum_{i=1}^n \omega_i
\tan\left[(0.5-p_i)\pi\right]\]</span> Here <span class="math inline">\(\omega_i\)</span> are weights that sum to one.
Given a standard Cauchy random variable W, we should have <span class="math display">\[\lim_{t\to\infty} \frac{P[X&gt;t]}{P[W&gt;t]} =
1\]</span> Thus, we can find a p-value for the tests together by
comparing <span class="math inline">\(X\)</span> to the quantiles of a
standard Cauchy distribution.</p>
</div>
<div class="section level3">
<h3 id="harmonic-mean-p-value">Harmonic Mean P-Value<a class="anchor" aria-label="anchor" href="#harmonic-mean-p-value"></a>
</h3>
<p>If p-values are not independent and the variance of the data is
unknown, the harmonic mean p-value (HMP) is often the best solution.
Given the p-values for our tests, the HMP is calculated as:</p>
<p><span class="math display">\[\dot p = \frac{\sum_{i=1}^n
w_i}{\sum_{i=1}^nw_i/p_i}\]</span> Here <span class="math inline">\(w_i\)</span> are the weights for each p-value such
the sum of weights adds to one. If all tests are equally weighted, then
<span class="math inline">\(w_i=1/n \;\forall i\)</span>.</p>
<p>The HMP is generally anti-conservative, but less so than Fisher’s
Method. The level of anti-conservativeness decreases with <span class="math inline">\(\dot p\)</span>, so low values of HMP have less
error. This is strong enough that HMP is directly interpretable at
levels of <span class="math inline">\(\dot p \leq 0.05\)</span>.</p>
<p>An asymptotically exact p-value can be calculated from the HMP <a href="https://en.wikipedia.org/wiki/Harmonic_mean_p-value#Asymptotically_exact_harmonic_mean_p-value_procedure" class="external-link">using
a Landau distribution</a>.</p>
<p>Note also that a multilevel test can be designed to use HMP at
subsets of the original tests while maintaining the FWER. Using HMP for
any subset <span class="math inline">\(S\)</span> of the p-values
rejecting at <span class="math inline">\(\dot p \leq \alpha\sum_{i\in S}
w_i\)</span> will approximately control the FWER at level <span class="math inline">\(\alpha\)</span>. This method can be used to find
significant subsets of the overall group of tests.</p>
<p>The HMP has a number of really great properties:</p>
<ul>
<li>Robust to positive dependency between p-values</li>
<li>Insensitive to number of tests</li>
<li>Robust to distribution of weights</li>
<li>Most influenced by smallest p-values</li>
<li>If HMP is not significant, neither are the HMPs of any subsets of
the tests</li>
<li>Controls FWER with lower FDR (greater power) than
Benjamini-Hochberg</li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="minimizing-fds-for-multiple-hypotheses">Minimizing FDS for Multiple Hypotheses<a class="anchor" aria-label="anchor" href="#minimizing-fds-for-multiple-hypotheses"></a>
</h2>
<p>These methods try to minimize the False Discovery Rate, generally
resulting in higher FWER but also higher statistical power. Note also
that FDS-based measures scale with the data–they try to limit
<em>proportion of overall false positives</em> rather than
<em>probability of at least one false positive</em>. Thus, more tests at
the same FDR will yield more false positives than more tests at the same
FWER.</p>
<div class="section level3">
<h3 id="benjamini-hochberg">Benjamini-Hochberg<a class="anchor" aria-label="anchor" href="#benjamini-hochberg"></a>
</h3>
<p>This method bears resemblance to the Hochberg step-up procedure, and
constrains the FDR to at most <span class="math inline">\(\alpha\)</span>. Like in Hochberg, we first sort
the p-values in ascending order. We then find the largest <span class="math inline">\(k\)</span> such that <span class="math inline">\(p_k \leq \frac{k}{n}\alpha\)</span>. The
corresponding null hypotheses <span class="math inline">\(H_1,\dots,H_k\)</span> are all rejected, while the
remaining null hypotheses cannot be rejected.</p>
<p>This procedure can be observed geometrically by first plotting <span class="math inline">\((k,p_k)\)</span> for all p-values, then drawing
the line <span class="math inline">\(y=\frac{\alpha}{n}x\)</span>. All
points below the line correspond to hypotheses that are rejected, and
all points above fail to reject.</p>
<p><img src="MultipleTesting_files/figure-html/unnamed-chunk-2-1.png" width="700">
Here the green points are those that we can reject the null hypothesis
for, and red are those we cannot.</p>
<p>Benjamini-Hochberg is valid when all tests are independent and for
some cases of dependence, but isn’t universally valid. If there is a
concern of dependence between values, use Benjamini-Yekutieli or HMP
instead.</p>
</div>
<div class="section level3">
<h3 id="benjamini-yekutieli">Benjamini-Yekutieli<a class="anchor" aria-label="anchor" href="#benjamini-yekutieli"></a>
</h3>
<p>Benjamini-Yekutieli improves on Benjamini-Hochberg by allowing for
good performance under arbitrary dependence scenarios. The algorithm is
the same, but modify our bound by checking for the largest <span class="math inline">\(k\)</span> such that <span class="math inline">\(p_k \leq \frac{k}{c(n)* n}\alpha\)</span>.</p>
<p><span class="math inline">\(c(n)\)</span> is a new parameter that is
defined as follows:</p>
<ul>
<li>If tests are independent or positively correlated, <span class="math inline">\(c(n) = 1\)</span>.</li>
<li>Otherwise, <span class="math inline">\(c(n) = \sum_{i=1}^n
n^{-1}\)</span>, the <span class="math inline">\(n^{th}\)</span>
harmonic number.</li>
</ul>
<p>For large values of <span class="math inline">\(n\)</span>, <span class="math inline">\(c(n) \approx \ln(n) + 0.57721 +
(2n)^{-1}\)</span>. The constant comes from the Euler-Mascheroni
constant (truncated here).</p>
</div>
</div>
<div class="section level2">
<h2 id="conclusions">Conclusions<a class="anchor" aria-label="anchor" href="#conclusions"></a>
</h2>
<p>A multitude of methods for a variety of applications are presented
here. The following table briefly summarizes the main takeaways.</p>
<table class="table">
<colgroup>
<col width="25%">
<col width="25%">
<col width="25%">
<col width="25%">
</colgroup>
<thead><tr class="header">
<th align="center">How many Hypotheses?</th>
<th align="center">Are Tests Independent?</th>
<th align="center">Minimize FWER or FDS?</th>
<th align="center">Test</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">Many</td>
<td align="center">Yes</td>
<td align="center">FWER</td>
<td align="center">Hochberg Step-up</td>
</tr>
<tr class="even">
<td align="center">Many</td>
<td align="center">No</td>
<td align="center">FWER</td>
<td align="center">Holm-Bonferroni</td>
</tr>
<tr class="odd">
<td align="center">Many</td>
<td align="center">–</td>
<td align="center">FDS</td>
<td align="center">Benjamini-Yekutieli</td>
</tr>
<tr class="even">
<td align="center">One</td>
<td align="center">–</td>
<td align="center">–</td>
<td align="center">HMP</td>
</tr>
</tbody>
</table>
</div>

  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Aidan Lakshman.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
